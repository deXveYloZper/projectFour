import warnings
warnings.filterwarnings("ignore", category=FutureWarning, message="`resume_download` is deprecated and will be removed in version 1.0.0")
warnings.filterwarnings("ignore", category=UserWarning, message="Some weights of the model checkpoint")

import sys
import json
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification

# Specify a model and tokenizer explicitly for NER
model_name = "dslim/bert-base-NER"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)
ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer)

def clean_text(text):
    """
    Preprocesses the text for better NER performance.
    
    Args:
    text (str): The job description text.

    Returns:
    str: Cleaned text.
    """
    # Perform any text cleaning here if necessary
    text = text.replace(">>", "").replace("â€¢", "")
    return text

def extract_requirements(text):
    """
    Extracts key requirements (skills, technologies, experience, environment) from the given job description text.

    Args:
    text (str): The job description text.

    Returns:
    dict: A dictionary categorizing the extracted requirements.
    """
    requirements = {
        "skills": [],
        "technologies": [],
        "experience": [],
        "environment": [],
        "others": []
    }

    # Preprocess the text
    text = clean_text(text)

    # Use the Transformers pipeline directly for NER
    ner_results = ner_pipeline(text)
    merged_entities = []

    current_entity = None
    current_entity_type = None

    for result in ner_results:
        entity_type = result["entity"]
        word = result["word"]

        # Handle subword tokens
        if word.startswith("##"):
            if current_entity is not None:
                current_entity += word[2:]
            else:
                current_entity = word[2:]
        else:
            if current_entity is not None:
                merged_entities.append((current_entity, current_entity_type))
                current_entity = None
                current_entity_type = None

            current_entity = word
            current_entity_type = entity_type

    # Append the last entity if present
    if current_entity is not None:
        merged_entities.append((current_entity, current_entity_type))

    # Enhanced categorization using context and heuristics
    for entity, entity_type in merged_entities:
        entity_type = entity_type.replace("B-", "").replace("I-", "")

        # Example heuristic rules
        if entity_type in ["ORG", "LOC"]:
            requirements["experience"].append(entity)
        elif any(kw in entity.lower() for kw in ["aws", "gcp", "azure", "kubernetes", "docker", "terraform"]):
            requirements["technologies"].append(entity)
        elif any(kw in entity.lower() for kw in ["python", "java", "c++", "golang", "javascript", "typescript"]):
            requirements["skills"].append(entity)
        elif entity_type in ["SKILL", "SOFT_SKILL", "PER"]:
            requirements["skills"].append(entity)
        elif entity_type in ["TECHNOLOGY", "TOOL"]:
            requirements["technologies"].append(entity)
        elif entity_type in ["ENVIRONMENT", "MISC"]:
            requirements["environment"].append(entity)
        else:
            requirements["others"].append(entity)

    return requirements

if __name__ == "__main__":
    job_description = sys.argv[1]
    requirements = extract_requirements(job_description)
    print(json.dumps(requirements, indent=2))
